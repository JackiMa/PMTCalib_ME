{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从生成的pdf能谱拟合数据中，批量提取出拟合信息\n",
    "\n",
    "注意，如果请在这一步时确保拟合的结果是OK的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# 设置日志配置\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "@dataclass\n",
    "class ParsedData:\n",
    "    mu: tuple\n",
    "    Q0: tuple\n",
    "    sigma0: tuple\n",
    "    Q1: tuple\n",
    "    sigma1: tuple\n",
    "    alpha: tuple\n",
    "    w: tuple\n",
    "    chi2_NDOF: tuple\n",
    "    fileName: str\n",
    "    isGood: int\n",
    "    HV: int\n",
    "\n",
    "class PDFDataExtractor:\n",
    "    def __init__(self, is_good_lower_bound=0.7, is_good_upper_bound=1.5, hv_pattern=r'led-(\\d+)--00'):\n",
    "        self.is_good_lower_bound = is_good_lower_bound\n",
    "        self.is_good_upper_bound = is_good_upper_bound\n",
    "        self.hv_pattern = hv_pattern\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path):\n",
    "        \"\"\"Extracts all text from a PDF file.\"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text += page.extract_text()\n",
    "            logging.info(f\"Successfully extracted text from {pdf_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return text\n",
    "\n",
    "    def find_data_between_keywords(self, text, start_keyword=\"seirtnE\", end_keyword=\"NDOF\"):\n",
    "        \"\"\"Finds and extracts the text between two keywords.\"\"\"\n",
    "        start_pos = text.find(start_keyword)\n",
    "        end_pos = text.find(end_keyword, start_pos) + 100\n",
    "        if start_pos == -1 or end_pos == -1:\n",
    "            return None\n",
    "        return text[start_pos:end_pos + len(end_keyword)]\n",
    "\n",
    "    def parse_data(self, data, file_name):\n",
    "        \"\"\"Parses the extracted data and returns a structured ParsedData object.\"\"\"\n",
    "        def extract_values(pattern, data):\n",
    "            match = pattern.search(data)\n",
    "            return match.groups() if match else (None, None)\n",
    "\n",
    "        try:\n",
    "            mu = extract_values(re.compile(r\"m\\s*=\\s*([\\d\\.\\-]+)\\s*–\\s*([\\d\\.\\-]+)\"), data)\n",
    "            Q0 = extract_values(re.compile(r\"Q0\\s*=\\s*([\\d\\.\\-]+)\\s*–\\s*([\\d\\.\\-]+)\"), data)\n",
    "            sigma0 = extract_values(re.compile(r\"s\\s*0\\s*=\\s*([\\d\\.\\-]+)\\s*–\\s*([\\d\\.\\-]+)\"), data)\n",
    "            Q1 = extract_values(re.compile(r\"Q1\\s*=\\s*([\\d\\.\\-]+)\\s*–\\s*([\\d\\.\\-]+)\"), data)\n",
    "            sigma1 = extract_values(re.compile(r\"s\\s*1\\s*=\\s*([\\d\\.\\-]+)\\s*–\\s*([\\d\\.\\-]+)\"), data)\n",
    "            alpha = extract_values(re.compile(r\"a\\s*=\\s*([\\d\\.\\-]+)\\s*–\\s*([\\d\\.\\-]+)\"), data)\n",
    "            w = extract_values(re.compile(r\"w\\s*=\\s*([\\d\\.\\-]+)\\s*–\\s*([\\d\\.\\-]+)\"), data)\n",
    "            chi2_NDOF = extract_values(re.compile(r\"c\\s*2/NDOF\\s*=\\s*([\\d\\.\\-]+)\\s*/\\s*([\\d\\.\\-]+)\"), data)\n",
    "\n",
    "            chi2_ratio = float(chi2_NDOF[0]) / float(chi2_NDOF[1]) if chi2_NDOF[0] and chi2_NDOF[1] else None\n",
    "            isGood = 1 if chi2_ratio and self.is_good_lower_bound <= chi2_ratio <= self.is_good_upper_bound else 0\n",
    "\n",
    "            hv_match = re.search(self.hv_pattern, file_name)\n",
    "            HV = int(hv_match.group(1)) if hv_match else None\n",
    "\n",
    "            logging.info(f\"Successfully parsed data from {file_name}\")\n",
    "            return ParsedData(mu, Q0, sigma0, Q1, sigma1, alpha, w, chi2_NDOF, file_name, isGood, HV)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error parsing data from {file_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_and_parse(self, pdf_path):\n",
    "        \"\"\"Extracts text from a PDF, finds the relevant data section, and parses it.\"\"\"\n",
    "        text = self.extract_text_from_pdf(pdf_path)\n",
    "        data_section = self.find_data_between_keywords(text)\n",
    "\n",
    "        if data_section:\n",
    "            return self.parse_data(data_section, pdf_path)\n",
    "        else:\n",
    "            logging.warning(f\"Data section not found in the document {pdf_path}.\")\n",
    "            return None\n",
    "\n",
    "def process_all_pdfs_in_directory(directory, extractor):\n",
    "    \"\"\"Processes all PDF files in the specified directory.\"\"\"\n",
    "    parsed_data_list = []\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory, file_name)\n",
    "            parsed_data = extractor.extract_and_parse(pdf_path)\n",
    "            if parsed_data:\n",
    "                parsed_data_list.append(parsed_data)\n",
    "\n",
    "    parsed_data_list.sort(key=lambda x: x.HV) # Sort the list based on HV\n",
    "    return parsed_data_list\n",
    "\n",
    "\n",
    "def create_combined_image(parsed_data_list, output_image_path, images_per_row=2, resolution=300, font_size=160):\n",
    "    \"\"\"Creates a combined image from all PDF files and highlights based on isGood.\"\"\"\n",
    "    images = []\n",
    "    for parsed_data in parsed_data_list:\n",
    "        try:\n",
    "            with pdfplumber.open(parsed_data.fileName) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    img = page.to_image(resolution=resolution).original  # Set resolution\n",
    "                    images.append((img, parsed_data.isGood, parsed_data.HV, parsed_data.fileName))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing image from {parsed_data.fileName}: {e}\")\n",
    "\n",
    "    if not images:\n",
    "        logging.error(\"No images to combine.\")\n",
    "        return\n",
    "\n",
    "    # Calculate the dimensions for the combined image\n",
    "    widths, heights = zip(*(img.size for img, _, _, _ in images))\n",
    "    max_width = max(widths)\n",
    "    max_height = max(heights)\n",
    "    num_rows = (len(images) + images_per_row - 1) // images_per_row  # Calculate the number of rows needed\n",
    "\n",
    "    combined_image_width = max_width * images_per_row\n",
    "    combined_image_height = max_height * num_rows\n",
    "\n",
    "    # Create a new blank image with the calculated dimensions\n",
    "    combined_image = Image.new('RGB', (combined_image_width, combined_image_height))\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "\n",
    "    # Load fonts\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "        small_font = ImageFont.truetype(\"arial.ttf\", font_size // 10)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "        small_font = ImageFont.load_default()\n",
    "        logging.warning(\"Default font loaded as 'arial.ttf' was not found.\")\n",
    "\n",
    "    # Paste each image into the combined image and draw the border\n",
    "    for i, (img, isGood, HV, fileName) in enumerate(images):\n",
    "        combined_image.paste(img, (x_offset, y_offset))\n",
    "        draw = ImageDraw.Draw(combined_image)\n",
    "        color = \"blue\" if isGood == 1 else \"red\"\n",
    "        draw.rectangle([x_offset, y_offset, x_offset + max_width, y_offset + max_height], outline=color, width=5)\n",
    "        \n",
    "        # Draw HV value at the bottom left corner\n",
    "        text_position = (x_offset + 0.2 * font_size, y_offset + max_height - 1.1 * font_size)\n",
    "        draw.text(text_position, f\"HV: {HV}\", fill=\"black\", font=font)\n",
    "\n",
    "        # Draw fileName below HV value\n",
    "        file_name_position = (x_offset + 4.8 * font_size, y_offset + max_height - 0.3*font_size)\n",
    "        draw.text(file_name_position, fileName, fill=\"black\", font=small_font)\n",
    "\n",
    "        x_offset += max_width\n",
    "        if (i + 1) % images_per_row == 0:\n",
    "            x_offset = 0\n",
    "            y_offset += max_height\n",
    "\n",
    "    # Save the combined image to the specified output path\n",
    "    combined_image.save(output_image_path)\n",
    "    logging.info(f\"Combined image saved to {output_image_path}\")\n",
    "\n",
    "\n",
    "def filter_and_print(parsed_data_list, hv_threshold):\n",
    "    \"\"\"Filters the parsed data based on HV threshold and prints the results.\"\"\"\n",
    "    filtered_list = [data for data in parsed_data_list if data.isGood == 1 and data.HV > hv_threshold]\n",
    "    for data in filtered_list:\n",
    "        print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 12:11:59,840 - INFO - Successfully extracted text from notia\\F1--pmt-notia-led-1000--00000_Gain=0.003462nVs.pdf\n",
      "2025-01-03 12:11:59,840 - INFO - Successfully parsed data from notia\\F1--pmt-notia-led-1000--00000_Gain=0.003462nVs.pdf\n",
      "2025-01-03 12:11:59,985 - INFO - Successfully extracted text from notia\\F1--pmt-notia-led-1100--00000_Gain=0.005533nVs.pdf\n",
      "2025-01-03 12:11:59,986 - INFO - Successfully parsed data from notia\\F1--pmt-notia-led-1100--00000_Gain=0.005533nVs.pdf\n",
      "2025-01-03 12:12:00,164 - INFO - Successfully extracted text from notia\\F1--pmt-notia-led-1200--00000_Gain=0.009006nVs.pdf\n",
      "2025-01-03 12:12:00,165 - INFO - Successfully parsed data from notia\\F1--pmt-notia-led-1200--00000_Gain=0.009006nVs.pdf\n",
      "2025-01-03 12:12:00,269 - INFO - Successfully extracted text from notia\\F1--pmt-notia-led-1300--00000_Gain=0.013138nVs.pdf\n",
      "2025-01-03 12:12:00,270 - INFO - Successfully parsed data from notia\\F1--pmt-notia-led-1300--00000_Gain=0.013138nVs.pdf\n",
      "2025-01-03 12:12:00,423 - INFO - Successfully extracted text from notia\\F1--pmt-notia-led-1400--00000_Gain=0.026517nVs.pdf\n",
      "2025-01-03 12:12:00,424 - INFO - Successfully parsed data from notia\\F1--pmt-notia-led-1400--00000_Gain=0.026517nVs.pdf\n",
      "2025-01-03 12:12:00,570 - INFO - Successfully extracted text from notia\\F1--pmt-notia-led-1500--00000_Gain=0.026714nVs.pdf\n",
      "2025-01-03 12:12:00,571 - INFO - Successfully parsed data from notia\\F1--pmt-notia-led-1500--00000_Gain=0.026714nVs.pdf\n",
      "2025-01-03 12:12:00,705 - INFO - Successfully extracted text from notia\\F1--pmt-notia-led-900--00002_Gain=0.003214nVs.pdf\n",
      "2025-01-03 12:12:00,706 - INFO - Successfully parsed data from notia\\F1--pmt-notia-led-900--00002_Gain=0.003214nVs.pdf\n",
      "2025-01-03 12:12:01,572 - INFO - Combined image saved to notia/combined_image.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedData(mu=('1.310', '0.022'), Q0=('-0.00026', '0.00005'), sigma0=('0.00172', '0.00003'), Q1=('0.00528', '0.00006'), sigma1=('0.00132', '0.00008'), alpha=('628', '797'), w=('0.000', '0.090'), chi2_NDOF=('387', '400'), fileName='notia\\\\F1--pmt-notia-led-1100--00000_Gain=0.005533nVs.pdf', isGood=1, HV=1100)\n",
      "ParsedData(mu=('1.530', '0.113'), Q0=('-0.00048', '0.00014'), sigma0=('0.00166', '0.00006'), Q1=('0.00852', '0.00015'), sigma1=('0.00197', '0.00020'), alpha=('251', '51'), w=('0.277', '0.107'), chi2_NDOF=('247', '290'), fileName='notia\\\\F1--pmt-notia-led-1200--00000_Gain=0.009006nVs.pdf', isGood=1, HV=1200)\n",
      "ParsedData(mu=('1.435', '0.029'), Q0=('-0.00049', '0.00004'), sigma0=('0.00170', '0.00003'), Q1=('0.01264', '0.00007'), sigma1=('0.00317', '0.00010'), alpha=('168', '71'), w=('0.116', '0.035'), chi2_NDOF=('270', '233'), fileName='notia\\\\F1--pmt-notia-led-1300--00000_Gain=0.013138nVs.pdf', isGood=1, HV=1300)\n",
      "ParsedData(mu=('1.404', '0.012'), Q0=('-0.00049', '0.00003'), sigma0=('0.00172', '0.00002'), Q1=('0.02603', '0.00011'), sigma1=('0.00657', '0.00012'), alpha=('58', '5'), w=('0.158', '0.014'), chi2_NDOF=('375', '423'), fileName='notia\\\\F1--pmt-notia-led-1400--00000_Gain=0.026517nVs.pdf', isGood=1, HV=1400)\n",
      "ParsedData(mu=('1.371', '0.015'), Q0=('-0.00043', '0.00003'), sigma0=('0.00171', '0.00003'), Q1=('0.02628', '0.00013'), sigma1=('0.00641', '0.00013'), alpha=('56', '7'), w=('0.146', '0.017'), chi2_NDOF=('419', '410'), fileName='notia\\\\F1--pmt-notia-led-1500--00000_Gain=0.026714nVs.pdf', isGood=1, HV=1500)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "directory = \"notia\"  # pdf文件所在目录\n",
    "hv_pattern = r'led-(\\d+)--00' # 从fileName中匹配HV值的正则表达式\n",
    "\n",
    "# 用于对拟合结果进行判断和过滤的参数\n",
    "is_good_lower_bound = 0.7 # chi2 ratio lower bound\n",
    "is_good_upper_bound = 1.5 # chi2 ratio upper bound\n",
    "hv_threshold = 1000  # HV threshold for filtering\n",
    "\n",
    "extractor = PDFDataExtractor(is_good_lower_bound, is_good_upper_bound, hv_pattern)\n",
    "parsed_data_list = process_all_pdfs_in_directory(directory, extractor)\n",
    "\n",
    "# for parsed_data in parsed_data_list:\n",
    "#     print(parsed_data)\n",
    "\n",
    "output_image_path = directory+\"/combined_image.png\"\n",
    "create_combined_image(parsed_data_list, output_image_path)\n",
    "filter_and_print(parsed_data_list, hv_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成适用于Mathematica做数据分析的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1ListM = { 0.00312, 0.00329, 0.00528, 0.00852, 0.01264, 0.02603, 0.02628 };\n",
      "Q1ListS = { 0.00024, 0.00015, 0.00006, 0.00015, 0.00007, 0.00011, 0.00013 };\n",
      "Q0ListM = { -0.00009, -0.00018, -0.00026, -0.00048, -0.00049, -0.00049, -0.00043 };\n",
      "Q0ListS = { 0.00003, 0.00018, 0.00005, 0.00014, 0.00004, 0.00003, 0.00003 };\n",
      "HVList = { 900, 1000, 1100, 1200, 1300, 1400, 1500 };\n"
     ]
    }
   ],
   "source": [
    "def format_parsed_data(parsed_data_list):\n",
    "    \"\"\"Formats parsed data into the specified structure.\"\"\"\n",
    "    Q1ListM = []\n",
    "    Q1ListS = []\n",
    "    Q0ListM = []\n",
    "    Q0ListS = []\n",
    "    HVList = []\n",
    "\n",
    "    for data in parsed_data_list:\n",
    "        Q1ListM.append(data.Q1[0])\n",
    "        Q1ListS.append(data.Q1[1])\n",
    "        Q0ListM.append(data.Q0[0])\n",
    "        Q0ListS.append(data.Q0[1])\n",
    "        HVList.append(data.HV)\n",
    "\n",
    "    formatted_data = {\n",
    "        \"Q1ListM\": Q1ListM,\n",
    "        \"Q1ListS\": Q1ListS,\n",
    "        \"Q0ListM\": Q0ListM,\n",
    "        \"Q0ListS\": Q0ListS,\n",
    "        \"HVList\": HVList\n",
    "    }\n",
    "\n",
    "    return formatted_data\n",
    "\n",
    "formatted_data = format_parsed_data(parsed_data_list)\n",
    "\n",
    "\n",
    "print(\"Q1ListM =\", \"{\", \", \".join(map(str, formatted_data[\"Q1ListM\"])), \"};\")\n",
    "print(\"Q1ListS =\", \"{\", \", \".join(map(str, formatted_data[\"Q1ListS\"])), \"};\")\n",
    "print(\"Q0ListM =\", \"{\", \", \".join(map(str, formatted_data[\"Q0ListM\"])), \"};\")\n",
    "print(\"Q0ListS =\", \"{\", \", \".join(map(str, formatted_data[\"Q0ListS\"])), \"};\")\n",
    "print(\"HVList =\", \"{\", \", \".join(map(str, formatted_data[\"HVList\"])), \"};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ParsedData(mu=('0.137', '0.001'), Q0=('0.00115', '0.00000'), sigma0=('0.00211', '0.00002'), Q1=('0.00421', '0.00009'), sigma1=('0.00015', '0.00013'), alpha=('53', '1562'), w=('0.000', '0.005'), chi2_NDOF=('266', '162'), fileName='notia\\\\F1--pmt-notia-led-900--00000_Gain=0.003060nVs.pdf', isGood=0, HV=900),\n",
       " ParsedData(mu=('0.090', '0.006'), Q0=('0.00021', '0.00002'), sigma0=('0.00181', '0.00002'), Q1=('0.00341', '0.00012'), sigma1=('0.00008', '0.00108'), alpha=('3965', '3463'), w=('0.000', '0.064'), chi2_NDOF=('151', '131'), fileName='notia\\\\F1--pmt-notia-led-900--00001_Gain=0.003198nVs.pdf', isGood=1, HV=900),\n",
       " ParsedData(mu=('0.058', '0.007'), Q0=('-0.00009', '0.00003'), sigma0=('0.00178', '0.00002'), Q1=('0.00312', '0.00024'), sigma1=('0.00006', '0.00385'), alpha=('136', '151'), w=('0.221', '0.164'), chi2_NDOF=('137', '120'), fileName='notia\\\\F1--pmt-notia-led-900--00002_Gain=0.003214nVs.pdf', isGood=1, HV=900),\n",
       " ParsedData(mu=('0.327', '0.000'), Q0=('0.00140', '0.00000'), sigma0=('0.00242', '0.00002'), Q1=('0.00570', '0.00005'), sigma1=('0.00027', '0.00003'), alpha=('8', '896'), w=('0.000', '0.001'), chi2_NDOF=('1042', '254'), fileName='notia\\\\F1--pmt-notia-led-1000--00000_Gain=0.004304nVs.pdf', isGood=0, HV=1000),\n",
       " ParsedData(mu=('0.870', '0.000'), Q0=('0.00104', '0.00004'), sigma0=('0.00257', '0.00003'), Q1=('0.00623', '0.00004'), sigma1=('0.00046', '0.00018'), alpha=('60', '22'), w=('0.012', '0.006'), chi2_NDOF=('1039', '400'), fileName='notia\\\\F1--pmt-notia-led-1100--00000_Gain=0.005187nVs.pdf', isGood=0, HV=1100),\n",
       " ParsedData(mu=('1.530', '0.113'), Q0=('-0.00048', '0.00014'), sigma0=('0.00166', '0.00006'), Q1=('0.00852', '0.00015'), sigma1=('0.00197', '0.00020'), alpha=('251', '51'), w=('0.277', '0.107'), chi2_NDOF=('247', '290'), fileName='notia\\\\F1--pmt-notia-led-1200--00000_Gain=0.009006nVs.pdf', isGood=1, HV=1200),\n",
       " ParsedData(mu=('1.435', '0.029'), Q0=('-0.00049', '0.00004'), sigma0=('0.00170', '0.00003'), Q1=('0.01264', '0.00007'), sigma1=('0.00317', '0.00010'), alpha=('168', '71'), w=('0.116', '0.035'), chi2_NDOF=('270', '233'), fileName='notia\\\\F1--pmt-notia-led-1300--00000_Gain=0.013138nVs.pdf', isGood=1, HV=1300),\n",
       " ParsedData(mu=('1.404', '0.012'), Q0=('-0.00049', '0.00003'), sigma0=('0.00172', '0.00002'), Q1=('0.02603', '0.00011'), sigma1=('0.00657', '0.00012'), alpha=('58', '5'), w=('0.158', '0.014'), chi2_NDOF=('375', '423'), fileName='notia\\\\F1--pmt-notia-led-1400--00000_Gain=0.026517nVs.pdf', isGood=1, HV=1400),\n",
       " ParsedData(mu=('1.371', '0.015'), Q0=('-0.00043', '0.00003'), sigma0=('0.00171', '0.00003'), Q1=('0.02628', '0.00013'), sigma1=('0.00641', '0.00013'), alpha=('56', '7'), w=('0.146', '0.017'), chi2_NDOF=('419', '410'), fileName='notia\\\\F1--pmt-notia-led-1500--00000_Gain=0.026714nVs.pdf', isGood=1, HV=1500)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
